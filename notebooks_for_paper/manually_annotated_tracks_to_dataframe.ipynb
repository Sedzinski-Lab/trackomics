{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "# -------------------------------------------\n",
    "# Imports and Utility Function Definitions\n",
    "# -------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from napatrackmater.Trackvector import (\n",
    "    TrackVector, SHAPE_FEATURES, DYNAMIC_FEATURES, SHAPE_DYNAMIC_FEATURES\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# -------------------------------------------\n",
    "# Helper Functions\n",
    "# -------------------------------------------\n",
    "\n",
    "def calculate_position_time(frame, time_interval):\n",
    "    \"\"\"Calculate time in seconds for a given frame and time interval.\"\"\"\n",
    "    if frame <= 119:\n",
    "        return frame * 1.49 * time_interval\n",
    "    elif frame <= 219:\n",
    "        return ((119 * 1.49 * time_interval) + ((frame - 119) * (2.00 * time_interval)))\n",
    "    else:\n",
    "        return ((119 * 1.49 * time_interval) + (100 * 2.00 * time_interval) + ((frame - 219) * (2.99 * time_interval)))\n",
    "\n",
    "def get_nucleus_centroid(nuc_label, t, full_nuc_array):\n",
    "    \"\"\"Compute centroid of a nucleus in a 3D labeled array at time t.\"\"\"\n",
    "    nuc_label = int(nuc_label)\n",
    "    t = int(t)\n",
    "    z_coords, y_coords, x_coords = np.where(full_nuc_array[t] == nuc_label)\n",
    "    if len(z_coords) > 0:\n",
    "        return np.mean(x_coords), np.mean(y_coords), np.mean(z_coords)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_membrane_centroid(mem_label, t, full_mem_array):\n",
    "    \"\"\"Compute centroid of a membrane in a 3D labeled array at time t.\"\"\"\n",
    "    mem_label = int(mem_label)\n",
    "    t = int(t)\n",
    "    z_coords, y_coords, x_coords = np.where(full_mem_array[t] == mem_label)\n",
    "    if len(z_coords) > 0:\n",
    "        return np.mean(x_coords), np.mean(y_coords), np.mean(z_coords)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def calculate_distance(row, centroid, coord_cols=('x', 'y', 'z')):\n",
    "    \"\"\"Calculate Euclidean distance between row coordinates and centroid.\"\"\"\n",
    "    return np.sqrt(sum((row[c] - centroid[i])**2 for i, c in enumerate(coord_cols)))\n",
    "\n",
    "def determine_cell_type(group):\n",
    "    \"\"\"Hierarchical rules to determine cell type for a group.\"\"\"\n",
    "    cell_types = set(group['cell_type'])\n",
    "    if len(cell_types) == 1:\n",
    "        single_cell_type = list(cell_types)[0]\n",
    "        if pd.notna(single_cell_type):\n",
    "            return single_cell_type\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    if 'basal' in cell_types and 'goblet' in cell_types:\n",
    "        return 'unknown'\n",
    "    if 'basal' in cell_types:\n",
    "        return 'basal'\n",
    "    if 'goblet' in cell_types:\n",
    "        return 'goblet'\n",
    "    return 'unknown'\n",
    "\n",
    "# -------------------------------------------\n",
    "# Directory and File Setup\n",
    "# -------------------------------------------\n",
    "channel = 'nuclei'\n",
    "tracking_directory = 'nuclei_membrane_tracking'\n",
    "data_frames_dir = os.path.join(tracking_directory, 'dataframes/')\n",
    "save_dir = tracking_directory  # Assuming save_dir is same as tracking_directory\n",
    "\n",
    "Path(save_dir).mkdir(exist_ok=True, parents=True)\n",
    "Path(data_frames_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "save_file = os.path.join(data_frames_dir, f'results_dataframe_{channel}.csv')\n",
    "\n",
    "# -------------------------------------------\n",
    "# Load DataFrames and Images\n",
    "# -------------------------------------------\n",
    "global_shape_dynamic_dataframe = pd.read_csv(save_file, index_col=0)\n",
    "global_shape_dynamic_dataframe['t_hours'] = [\n",
    "    calculate_position_time(t, 100) / 3600 for t in global_shape_dynamic_dataframe['t'].to_list()\n",
    "]\n",
    "\n",
    "man_spots2 = pd.read_csv(\n",
    "    'nuclei_membrane_tracking/MastodonTable_modeltesting-Spot.csv',\n",
    "    encoding='latin-1', low_memory=False\n",
    ")\n",
    "man_links2 = pd.read_csv(\n",
    "    'nuclei_membrane_tracking/MastodonTable_modeltesting-Link.csv',\n",
    "    encoding='latin-1', low_memory=False\n",
    ")\n",
    "man_branches2 = pd.read_csv(\n",
    "    'nuclei_membrane_tracking/MastodonTable_modeltesting-BranchSpot.csv',\n",
    "    encoding='latin-1', low_memory=False\n",
    ")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Preprocess Spot, Link, and Branch DataFrames\n",
    "# -------------------------------------------\n",
    "man_spots2 = man_spots2.iloc[2:,]\n",
    "man_links2 = man_links2.iloc[2:,]\n",
    "man_branches2 = man_branches2.iloc[2:,]\n",
    "\n",
    "for i in range(1, 4):\n",
    "    man_spots2.iloc[:, i] = pd.to_numeric(man_spots2.iloc[:, i]).astype('float')\n",
    "for i in range(4, 8):\n",
    "    man_spots2.iloc[:, i] = pd.to_numeric(man_spots2.iloc[:, i]).astype('float')\n",
    "for i in range(1, 7):\n",
    "    man_links2.iloc[:, i] = pd.to_numeric(man_links2.iloc[:, i]).astype('float', errors='ignore')\n",
    "\n",
    "man_spots2.rename(columns={\n",
    "    \"Spot position\": \"POSITION_X\",\n",
    "    \"Spot position.1\": \"POSITION_Y\",\n",
    "    \"Spot position.2\": \"POSITION_Z\"\n",
    "}, inplace=True)\n",
    "\n",
    "merged1 = man_spots2.merge(\n",
    "    man_links2[['Link target IDs', 'Link target IDs.1']],\n",
    "    left_on='ID', right_on='Link target IDs.1', how=\"left\"\n",
    ").drop(columns=['Link target IDs.1'])\n",
    "merged1.rename(columns={\"Link target IDs\": \"Spot source ID\"}, inplace=True)\n",
    "concatenated_df = merged1\n",
    "concatenated_branches = man_branches2\n",
    "\n",
    "# -------------------------------------------\n",
    "# Data Type Conversion and Track Relabeling\n",
    "# -------------------------------------------\n",
    "concatenated_df['ID'] = pd.to_numeric(concatenated_df['ID']).astype('int')\n",
    "concatenated_df['Spot frame'] = pd.to_numeric(concatenated_df['Spot frame']).astype('int')\n",
    "concatenated_df['Spot track ID'] = pd.to_numeric(concatenated_df['Spot track ID']).astype('int')\n",
    "concatenated_df['Spot source ID'] = pd.to_numeric(concatenated_df['Spot source ID'], errors='coerce').astype('Int32')\n",
    "\n",
    "unique_track_ids = concatenated_df['Spot track ID'].unique()\n",
    "new_track_id_mapping = {old_id: new_id for new_id, old_id in enumerate(unique_track_ids)}\n",
    "concatenated_df['Spot track ID relabelled'] = concatenated_df['Spot track ID'].map(new_track_id_mapping)\n",
    "\n",
    "duplicated_source_ids = concatenated_df.loc[\n",
    "    concatenated_df.duplicated(subset=['Spot source ID'], keep='first') &\n",
    "    ~(pd.isna(concatenated_df['Spot source ID'])), 'Spot source ID'\n",
    "].values\n",
    "concatenated_df['Dividing'] = concatenated_df['ID'].isin(duplicated_source_ids)\n",
    "\n",
    "unique_track_ids = concatenated_df['Spot track ID relabelled'].unique()\n",
    "concatenated_branches['Branch N spots'] = pd.to_numeric(concatenated_branches['Branch N spots']).astype('int')\n",
    "concatenated_branches['Branch depth'] = pd.to_numeric(concatenated_branches['Branch depth']).astype('int')\n",
    "\n",
    "# -------------------------------------------\n",
    "# Build Tracklets Dictionary\n",
    "# -------------------------------------------\n",
    "tracklets_dict = {}\n",
    "for track_id in tqdm(unique_track_ids):\n",
    "    og_track_id = concatenated_df[concatenated_df['Spot track ID relabelled'] == track_id]['Spot track ID'].values[0]\n",
    "    track_df = concatenated_df[concatenated_df['Spot track ID'] == og_track_id]\n",
    "    track_branches = concatenated_branches[concatenated_branches['Label'].isin(track_df['Label'].values)]\n",
    "    track_branches.reset_index(inplace=True)\n",
    "    for i in range(0, len(track_branches)):\n",
    "        tracklet_id = i\n",
    "        branch = track_branches.loc[i]\n",
    "        branch_label = branch['Label']\n",
    "        branch_spots_len = branch['Branch N spots']\n",
    "        generation = branch['Branch depth']\n",
    "        current_id = track_df.loc[track_df['Label'] == branch_label, 'ID'].values[0]\n",
    "        current_source_id = track_df.loc[track_df['Label'] == branch_label, 'Spot source ID'].values[0]\n",
    "        lineage_ids = [current_id]\n",
    "        for _ in range(branch_spots_len - 1):\n",
    "            next_id = track_df.loc[track_df['ID'] == current_source_id, 'ID'].values[0]\n",
    "            next_source_id = track_df.loc[track_df['ID'] == current_source_id, 'Spot source ID'].values[0]\n",
    "            lineage_ids.insert(0, next_id)\n",
    "            if not pd.isna(next_source_id):\n",
    "                current_source_id = next_source_id\n",
    "            else:\n",
    "                break\n",
    "        track_str = str(track_id) + str(generation) + str(tracklet_id)\n",
    "        tracklets_dict[track_str] = lineage_ids\n",
    "\n",
    "id_to_tracklet = {id_: tracklet_id for tracklet_id, ids in tracklets_dict.items() for id_ in ids}\n",
    "concatenated_df['Track ID'] = concatenated_df['ID'].map(id_to_tracklet)\n",
    "concatenated_df['Track ID numeric'] = concatenated_df['Track ID'].apply(int)\n",
    "\n",
    "# -------------------------------------------\n",
    "# Coordinate Conversion and Image Extraction\n",
    "# -------------------------------------------\n",
    "concatenated_df['X_orig'] = concatenated_df['POSITION_X'].astype('float') / 0.691\n",
    "concatenated_df['Y_orig'] = concatenated_df['POSITION_Y'].astype('float') / 0.691\n",
    "concatenated_df['Z_orig'] = concatenated_df['POSITION_Z'].astype('float') / 2\n",
    "\n",
    "gc.collect()\n",
    "full_nuc_array = tiff.imread('seg_nuclei_timelapses/timelapse_sixth_dataset.tif')\n",
    "\n",
    "concatenated_df.loc[:, 'Spot radius'] = pd.to_numeric(concatenated_df.loc[:, 'Spot radius'].astype(float))\n",
    "concatenated_df2 = concatenated_df[concatenated_df['Spot radius'] != 5.0]\n",
    "\n",
    "concatenated_df2['X_idx'] = concatenated_df2['X_orig'].round(0).astype(int)\n",
    "concatenated_df2['Y_idx'] = concatenated_df2['Y_orig'].round(0).astype(int)\n",
    "concatenated_df2['Z_idx'] = concatenated_df2['Z_orig'].round(0).astype(int)\n",
    "concatenated_df2['t_idx'] = concatenated_df2['Spot frame'].astype(int)\n",
    "concatenated_df2['nuc_label'] = concatenated_df2.apply(\n",
    "    lambda row: full_nuc_array[row['t_idx'], row['Z_idx'], row['Y_idx'], row['X_idx']], axis=1\n",
    ")\n",
    "concatenated_df2 = concatenated_df2.drop(columns=['X_idx', 'Y_idx', 'Z_idx', 't_idx'])\n",
    "concatenated_df3 = concatenated_df2[concatenated_df2['nuc_label'] != 0]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Manual Annotation and Cell Type Assignment\n",
    "# -------------------------------------------\n",
    "gt_df = pd.read_csv('manual_labeled_cells_sixth_dataset_updated.csv')\n",
    "gt_df_crop = gt_df.loc[\n",
    "    (gt_df['cell_type'] == 'basal') | (gt_df['cell_type'] == 'goblet'),\n",
    "    ['Centroid.X', 'Centroid.Y', 'Centroid.Z', 'cell_type']\n",
    "]\n",
    "gt_df_crop['Label'] = gt_df_crop.apply(\n",
    "    lambda row: full_nuc_array[-1][int(row['Centroid.Z']), int(row['Centroid.Y']), int(row['Centroid.X'])], axis=1\n",
    ")\n",
    "\n",
    "man_spots_ann_final = concatenated_df3[concatenated_df3['Spot frame'] == 359]\n",
    "concatenated_merged_final = pd.merge(\n",
    "    man_spots_ann_final, gt_df[['Label', 'cell_type']],\n",
    "    left_on='nuc_label', right_on='Label', how='left'\n",
    ")\n",
    "\n",
    "mapping_dict = concatenated_merged_final.groupby('Spot track ID relabelled').apply(determine_cell_type).to_dict()\n",
    "concatenated_df3['cell_type'] = concatenated_df3['Spot track ID relabelled'].map(mapping_dict)\n",
    "\n",
    "# Further assignment of 'cell_type' based on other columns\n",
    "concatenated_df3['cell_type'] = np.where(\n",
    "    concatenated_df3['celltypes'] == \"1\", 'mcc',\n",
    "    np.where(\n",
    "        concatenated_df3['celltypes.3'] == \"1\", 'ssc',\n",
    "        np.where(\n",
    "            concatenated_df3['celltypes.5'] == \"1\", 'ic',\n",
    "            np.where(\n",
    "                concatenated_df3['celltypes.7'] == \"1\", 'basal',\n",
    "                np.where(\n",
    "                    concatenated_df3['celltypes.9'] == \"1\", 'goblet',\n",
    "                    np.where(\n",
    "                        concatenated_df3['celltypes.13'] == \"1\", 'basal',\n",
    "                        np.where(\n",
    "                            concatenated_df3['celltypes.16'] == \"1\", 'goblet',\n",
    "                            concatenated_df3['cell_type']\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "concatenated_df3['cell_type'] = concatenated_df3['cell_type'].fillna('unknown')\n",
    "\n",
    "# Annotation column\n",
    "concatenated_df3['annotation'] = pd.NA\n",
    "concatenated_df3['annotation'] = np.where(\n",
    "    concatenated_df3['celltypes'] == \"1\", 'manual',\n",
    "    np.where(\n",
    "        concatenated_df3['celltypes.3'] == \"1\", 'manual',\n",
    "        np.where(\n",
    "            concatenated_df3['celltypes.5'] == \"1\", 'manual',\n",
    "            np.where(\n",
    "                concatenated_df3['celltypes.7'] == \"1\", 'manual',\n",
    "                np.where(\n",
    "                    concatenated_df3['celltypes.9'] == \"1\", 'manual',\n",
    "                    np.where(\n",
    "                        concatenated_df3['celltypes.13'] == \"1\", 'manual',\n",
    "                        np.where(\n",
    "                            concatenated_df3['celltypes.9'] == \"1\", 'manual',\n",
    "                            concatenated_df3['annotation']\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "concatenated_df3['annotation'] = concatenated_df3['annotation'].fillna('automatic')\n",
    "concatenated_df3['t_hours'] = [\n",
    "    calculate_position_time(t, 100) / 3600 for t in concatenated_df3['Spot frame'].to_list()\n",
    "]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Prepare Final DataFrames for Export\n",
    "# -------------------------------------------\n",
    "concatenated_df4 = concatenated_df3[[\n",
    "    'ID', 'Spot frame', 't_hours', 'POSITION_X', 'POSITION_Y', 'POSITION_Z',\n",
    "    'Spot track ID', 'Spot source ID', 'Spot track ID relabelled', 'Dividing',\n",
    "    'Track ID', 'Track ID numeric', 'X_orig', 'Y_orig', 'Z_orig', 'nuc_label',\n",
    "    'cell_type', 'annotation'\n",
    "]]\n",
    "concatenated_df4_manual = concatenated_df4[concatenated_df4['annotation'] == 'manual']\n",
    "concatenated_df4_manual.to_csv('all_manually_labelled_tracks_sixth_dataset.csv')\n",
    "\n",
    "# -------------------------------------------\n",
    "# Assign Nucleus Labels to Global DataFrame\n",
    "# -------------------------------------------\n",
    "global_shape_dynamic_dataframe['X_idx'] = global_shape_dynamic_dataframe['x'].astype('int')\n",
    "global_shape_dynamic_dataframe['Y_idx'] = global_shape_dynamic_dataframe['y'].astype('int')\n",
    "global_shape_dynamic_dataframe['Z_idx'] = global_shape_dynamic_dataframe['z'].astype('int')\n",
    "global_shape_dynamic_dataframe['t_idx'] = global_shape_dynamic_dataframe['t'].astype('int')\n",
    "global_shape_dynamic_dataframe['nuc_label'] = global_shape_dynamic_dataframe.apply(\n",
    "    lambda row: full_nuc_array[\n",
    "        row['t_idx'], row['Z_idx'], row['Y_idx'], row['X_idx']\n",
    "    ], axis=1\n",
    ")\n",
    "global_shape_dynamic_dataframe = global_shape_dynamic_dataframe.drop(\n",
    "    columns=['X_idx', 'Y_idx', 'Z_idx', 't_idx']\n",
    ")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Remove Duplicates by Closest to Centroid (Nucleus)\n",
    "# -------------------------------------------\n",
    "for t_value, nuc_label_value in tqdm(\n",
    "    global_shape_dynamic_dataframe[\n",
    "        global_shape_dynamic_dataframe.duplicated(subset=['t', 'nuc_label'], keep=False)\n",
    "    ][['t', 'nuc_label']].drop_duplicates().values\n",
    "):\n",
    "    centroid = get_nucleus_centroid(nuc_label_value, t_value, full_nuc_array)\n",
    "    if centroid is not None:\n",
    "        subset_df = global_shape_dynamic_dataframe[\n",
    "            (global_shape_dynamic_dataframe['t'] == t_value) &\n",
    "            (global_shape_dynamic_dataframe['nuc_label'] == nuc_label_value)\n",
    "        ]\n",
    "        subset_df['distance_to_centroid'] = subset_df.apply(\n",
    "            lambda row: calculate_distance(row, centroid, ('x', 'y', 'z')), axis=1\n",
    "        )\n",
    "        closest_idx = subset_df['distance_to_centroid'].idxmin()\n",
    "        global_shape_dynamic_dataframe.loc[\n",
    "            subset_df.index.difference([closest_idx]), 'nuc_label'\n",
    "        ] = np.nan\n",
    "\n",
    "for t_value, nuc_label_value in tqdm(\n",
    "    concatenated_df3[\n",
    "        concatenated_df3.duplicated(subset=['Spot frame', 'nuc_label'], keep=False)\n",
    "    ][['Spot frame', 'nuc_label']].drop_duplicates().values\n",
    "):\n",
    "    centroid = get_nucleus_centroid(nuc_label_value, t_value, full_nuc_array)\n",
    "    if centroid is not None:\n",
    "        subset_df = concatenated_df3[\n",
    "            (concatenated_df3['Spot frame'] == t_value) &\n",
    "            (concatenated_df3['nuc_label'] == nuc_label_value)\n",
    "        ]\n",
    "        subset_df['distance_to_centroid'] = subset_df.apply(\n",
    "            lambda row: calculate_distance(row, centroid, ('X_orig', 'Y_orig', 'Z_orig')), axis=1\n",
    "        )\n",
    "        closest_idx = subset_df['distance_to_centroid'].idxmin()\n",
    "        concatenated_df3.loc[\n",
    "            subset_df.index.difference([closest_idx]), 'nuc_label'\n",
    "        ] = np.nan\n",
    "\n",
    "filtered_concatenated_df = concatenated_df3[pd.notna(concatenated_df3['nuc_label'])]\n",
    "filtered_concatenated_df2 = filtered_concatenated_df[[\n",
    "    'ID', 'Spot frame', 'POSITION_X', 'POSITION_Y', 'POSITION_Z',\n",
    "    'Spot source ID', 'Spot track ID relabelled', 'Track ID', 'Track ID numeric',\n",
    "    'cell_type', 'X_orig', 'Y_orig', 'Z_orig', 'nuc_label', 'annotation'\n",
    "]]\n",
    "filtered_concatenated_df2.to_csv('for_Ziwei_new2.csv')\n",
    "\n",
    "# -------------------------------------------\n",
    "# Merge with Global Shape/Dynamic DataFrame\n",
    "# -------------------------------------------\n",
    "global_shape_dynamic_dataframe_merge = pd.merge(\n",
    "    global_shape_dynamic_dataframe,\n",
    "    filtered_concatenated_df2,\n",
    "    left_on=['t', 'nuc_label'], right_on=['Spot frame', 'nuc_label'], how='right'\n",
    ")\n",
    "global_shape_dynamic_dataframe_merge = global_shape_dynamic_dataframe_merge.drop_duplicates(\n",
    "    subset=['x', 'y', 'z', 't', 'Track ID_x'], keep='first'\n",
    ").reset_index(drop=True)\n",
    "global_shape_dynamic_dataframe_merge['t_hours'] = [\n",
    "    calculate_position_time(t, 100) / 3600 for t in global_shape_dynamic_dataframe_merge['Spot frame'].to_list()\n",
    "]\n",
    "global_shape_dynamic_dataframe_merge.to_csv(\n",
    "    'nuclei_membrane_tracking/nuclei_manual_dataset_withid.csv'\n",
    ")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Membrane Data Processing\n",
    "# -------------------------------------------\n",
    "del full_nuc_array\n",
    "gc.collect()\n",
    "\n",
    "nuc_mem_overlap = pd.read_csv('mem_nuc_overlap_table.csv')\n",
    "global_shape_dynamic_dataframe_membrane = pd.read_csv(\n",
    "    'nuclei_membrane_tracking/membrane_results_df.csv'\n",
    ")\n",
    "full_mem_array = tiff.imread('seg_membrane_timelapses_fixed/timelapse_sixth_dataset.tif')\n",
    "\n",
    "global_shape_dynamic_dataframe_membrane['X_idx'] = global_shape_dynamic_dataframe_membrane['x'].astype('int')\n",
    "global_shape_dynamic_dataframe_membrane['Y_idx'] = global_shape_dynamic_dataframe_membrane['y'].astype('int')\n",
    "global_shape_dynamic_dataframe_membrane['Z_idx'] = global_shape_dynamic_dataframe_membrane['z'].astype('int')\n",
    "global_shape_dynamic_dataframe_membrane['t_idx'] = global_shape_dynamic_dataframe_membrane['t'].astype('int')\n",
    "global_shape_dynamic_dataframe_membrane['mem_label'] = global_shape_dynamic_dataframe_membrane.apply(\n",
    "    lambda row: full_mem_array[\n",
    "        row['t_idx'], row['Z_idx'], row['Y_idx'], row['X_idx']\n",
    "    ], axis=1\n",
    ")\n",
    "global_shape_dynamic_dataframe_membrane = global_shape_dynamic_dataframe_membrane.drop(\n",
    "    columns=['X_idx', 'Y_idx', 'Z_idx', 't_idx']\n",
    ")\n",
    "global_shape_dynamic_dataframe_membrane2 = global_shape_dynamic_dataframe_membrane[\n",
    "    global_shape_dynamic_dataframe_membrane['mem_label'] != 0\n",
    "]\n",
    "\n",
    "for t_value, mem_label_value in tqdm(\n",
    "    global_shape_dynamic_dataframe_membrane2[\n",
    "        global_shape_dynamic_dataframe_membrane2.duplicated(subset=['t', 'mem_label'], keep=False)\n",
    "    ][['t', 'mem_label']].drop_duplicates().values\n",
    "):\n",
    "    centroid = get_membrane_centroid(mem_label_value, t_value, full_mem_array)\n",
    "    if centroid is not None:\n",
    "        subset_df = global_shape_dynamic_dataframe_membrane2[\n",
    "            (global_shape_dynamic_dataframe_membrane2['t'] == t_value) &\n",
    "            (global_shape_dynamic_dataframe_membrane2['mem_label'] == mem_label_value)\n",
    "        ]\n",
    "        subset_df['distance_to_centroid'] = subset_df.apply(\n",
    "            lambda row: calculate_distance(row, centroid, ('x', 'y', 'z')), axis=1\n",
    "        )\n",
    "        closest_idx = subset_df['distance_to_centroid'].idxmin()\n",
    "        global_shape_dynamic_dataframe_membrane2.loc[\n",
    "            subset_df.index.difference([closest_idx]), 'mem_label'\n",
    "        ] = np.nan\n",
    "\n",
    "global_shape_dynamic_dataframe_membrane2 = global_shape_dynamic_dataframe_membrane2.merge(\n",
    "    nuc_mem_overlap[['mem_label', 'nuc_label', 't']], on=['t', 'mem_label'], how='left'\n",
    ")\n",
    "global_shape_dynamic_dataframe_merge_membrane = pd.merge(\n",
    "    global_shape_dynamic_dataframe_membrane2,\n",
    "    filtered_concatenated_df2[[\n",
    "        'Spot frame', 'POSITION_X', 'POSITION_Y', 'POSITION_Z',\n",
    "        'Spot track ID relabelled', 'Track ID', 'Track ID numeric',\n",
    "        'cell_type', 'X_orig', 'Y_orig', 'Z_orig', 'nuc_label', 'annotation'\n",
    "    ]],\n",
    "    left_on=['t', 'nuc_label'], right_on=['Spot frame', 'nuc_label'], how='right'\n",
    ")\n",
    "global_shape_dynamic_dataframe_merge_membrane.to_csv(\n",
    "    'nuclei_membrane_tracking/membrane_manual_dataset.csv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kapoorlabsenv3",
   "language": "python",
   "name": "kapoorlabsenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
